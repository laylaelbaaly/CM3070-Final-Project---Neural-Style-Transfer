# -*- coding: utf-8 -*-
"""aspm_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uyJp1coxqTknpIz35EC_13gfTi4bDvHP
"""

import os
from typing import Optional
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms
import torchvision.utils as vutils

# Device + Transforms
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

to_tensor = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(256),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

to_pil = transforms.ToPILImage()

def vgg_denorm(tensor):
    mean = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1).to(device)
    std = torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1).to(device)
    return tensor * std + mean

# VGG Encoder
class VGGEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        vgg = models.vgg19(pretrained=True).features
        self.enc = nn.Sequential(*list(vgg.children())[:21])
        for param in self.parameters():
            param.requires_grad = False

    def forward(self, x):
        return self.enc(x)

# AdaIN alignment
def adain(c_feat, s_feat, eps=1e-5):
    c_mean, c_std = c_feat.mean([2, 3], keepdim=True), c_feat.std([2, 3], keepdim=True)
    s_mean, s_std = s_feat.mean([2, 3], keepdim=True), s_feat.std([2, 3], keepdim=True)
    return (c_feat - c_mean) / (c_std + eps) * s_std + s_mean

# Decoder
class Decoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.decoder = nn.Sequential(
            nn.ReflectionPad2d(1),
            nn.Conv2d(512, 256, 3),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode='nearest'),

            nn.ReflectionPad2d(1),
            nn.Conv2d(256, 256, 3),
            nn.ReLU(inplace=True),
            nn.ReflectionPad2d(1),
            nn.Conv2d(256, 256, 3),
            nn.ReLU(inplace=True),
            nn.ReflectionPad2d(1),
            nn.Conv2d(256, 256, 3),
            nn.ReLU(inplace=True),

            nn.ReflectionPad2d(1),
            nn.Conv2d(256, 128, 3),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode='nearest'),

            nn.ReflectionPad2d(1),
            nn.Conv2d(128, 128, 3),
            nn.ReLU(inplace=True),
            nn.ReflectionPad2d(1),
            nn.Conv2d(128, 64, 3),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode='nearest'),

            nn.ReflectionPad2d(1),
            nn.Conv2d(64, 64, 3),
            nn.ReLU(inplace=True),
            nn.ReflectionPad2d(1),
            nn.Conv2d(64, 3, 3)  # Final image output
        )

    def forward(self, x):
        return self.decoder(x)

# Image stylization API
@torch.inference_mode()
def stylize_adain_image(
    content_image_path: str,
    style_image_path: str,
    decoder_path: str,
    output_path: Optional[str] = None,
    alpha: float = 1.0):

    # Load & prep images
    content_img = Image.open(content_image_path).convert("RGB")
    style_img   = Image.open(style_image_path).convert("RGB")
    content = to_tensor(content_img).unsqueeze(0).to(device)
    style   = to_tensor(style_img).unsqueeze(0).to(device)

    # Load networks
    encoder = VGGEncoder().to(device).eval()
    decoder = Decoder().to(device)
    state = torch.load(decoder_path, map_location=device)

    if isinstance(state, dict) and "decoder_state_dict" in state:
        decoder.load_state_dict(state["decoder_state_dict"])
    else:
        decoder.load_state_dict(state)

    decoder.eval()

    # Stylize
    c_feat = encoder(content)
    s_feat = encoder(style)
    t = adain(c_feat, s_feat)
    t = alpha * t + (1 - alpha) * c_feat
    output = decoder(t)

    # Denormalize to [0,1] and convert to PIL
    output = vgg_denorm(output).clamp(0, 1).cpu().squeeze(0)   # CHW
    out_pil = to_pil(output)

    if output_path:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        vutils.save_image(output, output_path)

    return out_pil