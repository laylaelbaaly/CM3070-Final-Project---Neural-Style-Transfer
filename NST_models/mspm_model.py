# -*- coding: utf-8 -*-
"""mspm_model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YsahRe4t2-WTmb45N5jmm46HzkamU-U9
"""

import os
from typing import Optional
from PIL import Image
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms

# ---------- Model pieces ----------
class ConditionalInstanceNorm2d(nn.Module):
    def __init__(self, num_features, num_styles):
        super().__init__()
        self.num_styles = num_styles
        self.num_features = num_features

        self.gamma = nn.Embedding(num_styles, num_features)
        self.beta  = nn.Embedding(num_styles, num_features)

        nn.init.ones_(self.gamma.weight)
        nn.init.zeros_(self.beta.weight)

        self.instance_norm = nn.InstanceNorm2d(num_features, affine=False)

    def forward(self, x, style_id):
        x_norm = self.instance_norm(x)

        # Interpolation Support
        if isinstance(style_id, tuple):
            sid1, sid2, alpha = style_id  # sid1/sid2: LongTensor[B], alpha: float in [0,1]
            gamma1 = self.gamma(sid1).view(-1, self.num_features, 1, 1)
            beta1  = self.beta(sid1).view(-1,  self.num_features, 1, 1)
            gamma2 = self.gamma(sid2).view(-1, self.num_features, 1, 1)
            beta2  = self.beta(sid2).view(-1,  self.num_features, 1, 1)

            # Blend
            gamma = (1.0 - alpha) * gamma1 + alpha * gamma2
            beta  = (1.0 - alpha) * beta1  + alpha * beta2
        else:
            gamma = self.gamma(style_id).view(-1, self.num_features, 1, 1)
            beta  = self.beta(style_id).view(-1,  self.num_features, 1, 1)

        return gamma * x_norm + beta

class ResidualBlock(nn.Module):
    def __init__(self, channels, num_styles):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, 1, 1, padding_mode='reflect')
        self.in1   = ConditionalInstanceNorm2d(channels, num_styles)
        self.conv2 = nn.Conv2d(channels, channels, 3, 1, 1, padding_mode='reflect')
        self.in2   = ConditionalInstanceNorm2d(channels, num_styles)

    def forward(self, x, style_id):
        r = x
        x = F.relu(self.in1(self.conv1(x), style_id))
        x = self.in2(self.conv2(x), style_id)
        return x + r

# Style Transfer Network

class StyleTransferNet(nn.Module):
    def __init__(self, num_styles):
        super().__init__()

        # Encoder
        self.conv1 = nn.Conv2d(3, 32, kernel_size=9, stride=1, padding=4, padding_mode='reflect')
        self.in1 = ConditionalInstanceNorm2d(32, num_styles)

        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, padding_mode='reflect')
        self.in2 = ConditionalInstanceNorm2d(64, num_styles)

        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, padding_mode='reflect')
        self.in3 = ConditionalInstanceNorm2d(128, num_styles)

        # Residual blocks
        self.res_blocks = nn.ModuleList([ResidualBlock(128, num_styles) for _ in range(5)])

        # Decoder (Upsampling + Convolution)
        self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')
        self.deconv1 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1, padding_mode='reflect')
        self.in4 = ConditionalInstanceNorm2d(64, num_styles)

        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')
        self.deconv2 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1, padding_mode='reflect')
        self.in5 = ConditionalInstanceNorm2d(32, num_styles)

        # Output layer
        self.conv_out = nn.Conv2d(32, 3, kernel_size=9, stride=1, padding=4, padding_mode='reflect')

    def forward(self, x, style_id):
        x = F.relu(self.in1(self.conv1(x), style_id))
        x = F.relu(self.in2(self.conv2(x), style_id))
        x = F.relu(self.in3(self.conv3(x), style_id))

        for res_block in self.res_blocks:
            x = res_block(x, style_id)

        x = self.upsample1(x)
        x = F.relu(self.in4(self.deconv1(x), style_id))

        x = self.upsample2(x)
        x = F.relu(self.in5(self.deconv2(x), style_id))

        x = torch.sigmoid(self.conv_out(x))  # Final sigmoid activation
        return x

# ---------- Helpers ----------

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([transforms.Resize(256),
                                transforms.CenterCrop(256),
                                transforms.ToTensor()])
to_pil = transforms.ToPILImage()

num_styles = 5   # Starry, Visitor, Great Wave, Composition, Water Lilies
model: Optional[nn.Module] = None #for caching

def load_model(model_path) -> nn.Module:
    global model
    if model is not None:
        return model

    model = StyleTransferNet(num_styles).to(device)
    state = torch.load(model_path, map_location=device)
    model.load_state_dict(state)
    model.eval()
    return model

@torch.inference_mode()
def stylize_image(model_path, content_image_path, style_id, output_path=None):

    m = load_model(model_path)
    img = Image.open(content_image_path).convert("RGB")
    x = transform(img).unsqueeze(0).to(device)
    sid = torch.tensor([int(style_id)], device=device)
    y = m(x, sid).clamp(0, 1)
    out = to_pil(y.squeeze(0).cpu())

    if output_path:
        out.save(output_path)

    return out

@torch.inference_mode()
def stylize_image_interpolated(model: nn.Module,
                               content_image_path: str,
                               style_id1: int,
                               style_id2: int,
                               alpha: float,
                               output_path: Optional[str] = None):
    # Preprocess
    content_img = Image.open(content_image_path).convert("RGB")
    content_tensor = transform(content_img).unsqueeze(0).to(device)

    B = 1
    sid1_tensor = torch.tensor([int(style_id1)] * B, device=device)
    sid2_tensor = torch.tensor([int(style_id2)] * B, device=device)

    m = model.eval()
    y = m(content_tensor, (sid1_tensor, sid2_tensor, float(alpha))).clamp(0, 1)

    out = to_pil(y.squeeze(0).cpu())

    if output_path:
        Path(os.path.dirname(output_path) or ".").mkdir(parents=True, exist_ok=True)
        out.save(output_path)

    return out