# -*- coding: utf-8 -*-
"""starry_pspm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19JK3rqZbe68d7gW7faJV2U4JY9IPbJVT
"""

# starry_pspm.py

import os
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
from typing import Optional

# ---------------------------
# Model components
# ---------------------------

def gram_matrix(tensor):
    B, C, H, W = tensor.size()
    features = tensor.view(B, C, H * W)
    G = torch.bmm(features, features.transpose(1, 2))
    return G / (C * H * W)

class ConvLayer(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride):
        super().__init__()
        padding = kernel_size // 2
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        self.norm = nn.InstanceNorm2d(out_channels, affine=True)
        self.relu = nn.ReLU()

    def forward(self, x):
        return self.relu(self.norm(self.conv(x)))

class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.block = nn.Sequential(
            ConvLayer(channels, channels, 3, 1),
            ConvLayer(channels, channels, 3, 1),
        )

    def forward(self, x):
        return x + self.block(x)

class UpsampleConvLayer(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, scale_factor):
        super().__init__()
        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='nearest')
        self.conv = ConvLayer(in_channels, out_channels, kernel_size, 1)

    def forward(self, x):
        x = self.upsample(x)
        return self.conv(x)

class TransformerNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            ConvLayer(3, 32, 9, 1),
            ConvLayer(32, 64, 3, 2),
            ConvLayer(64, 128, 3, 2),
            ResidualBlock(128),
            ResidualBlock(128),
            ResidualBlock(128),
            ResidualBlock(128),
            ResidualBlock(128),
            UpsampleConvLayer(128, 64, 3, 2),
            UpsampleConvLayer(64, 32, 3, 2),
            nn.Conv2d(32, 3, 9, 1, padding=4)  # no tanh; output unclamped
        )

    def forward(self, x):
        return self.model(x)

# ---------------------------
# Pre/post-processing
# ---------------------------

#Transform
# Resize(256) -> CenterCrop(256) -> ToTensor() -> Normalize(IMAGENET)
preprocess_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(256),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

def preprocess_image(pil_img: Image.Image) -> torch.Tensor:
    return preprocess_transform(pil_img).unsqueeze(0)

def deprocess_to_pil(t: torch.Tensor) -> Image.Image:
    # Unnormalize + clamp + CHW->HWC -> PIL
    t = t.detach().float().cpu().squeeze(0)  # [3,H,W]
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std  = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    t = t * std + mean
    t = t.clamp(0, 1)
    t = t.permute(1, 2, 0).numpy()  # HWC, [0,1]
    return Image.fromarray((t * 255).astype("uint8"))

# ---------------------------
# Load model
# ---------------------------

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODELS: dict[str, nn.Module] = {}

def load_starry_model(weights_path: str):

    if not os.path.isfile(weights_path):
        raise FileNotFoundError(f"PSPM weights not found: {weights_path}")

    model = MODELS.get(weights_path)
    if model is not None:
        return model

    model = TransformerNet().to(DEVICE).eval()
    state_dict = torch.load(weights_path, map_location=DEVICE)

    if isinstance(state_dict, dict) and "state_dict" in state_dict:
        state_dict = state_dict["state_dict"]

    model.load_state_dict(state_dict, strict=True)

    MODELS[weights_path] = model
    return model

# ---------------------------
# Stylize image
# ---------------------------

@torch.inference_mode()
def stylize_image(model_path: str,
                  content_image_path: str,
                  output_path: Optional[str] = None):

    model = load_starry_model(model_path)

    content_img = Image.open(content_image_path).convert("RGB")
    content_tensor = preprocess_image(content_img).to(DEVICE)

    stylized_tensor = model(content_tensor)

    out_pil = deprocess_to_pil(stylized_tensor)

    if output_path:
        out_pil.save(output_path)

    return out_pil